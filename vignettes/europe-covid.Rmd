---
title: Multilevel Modeling  
output:
  bookdown::html_document2:
    theme: flatly
link-citations: yes
bibliography: ../inst/REFERENCES.bib
pkgdown:
  as_is: true
---

<style>
.contents .page-header {
    display: none;
  } 
</style>

<div class = "article_container">

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  out.width = 6, fig.height = 6, out.width = "70%", fig.align = "center"
)
library(ggplot2)
```



# Effects of Interventions on Covid-19 <img src='../man/figures/logo.png' class = "small_logo" align="right"/>
<hr>

The Spanish flu [example](flu.html) considered inferring the instantaneous 
reproduction number over time in a single population. Here, we demonstrate some 
of the more advanced modeling capabilities of the package. We strongly recommend 
reviewing the H1N1 [vignette](flu.html) before continuing with this article. 

Consider modeling the evolution of an epidemic in multiple regions. Of course, 
one can always specify separate models for each group. This approach is fast; 
each model can be fit independently in parallel. Nonetheless, often there is 
little high quality data for some groups, and the data does little to inform 
parameter estimates. This is particularly true in the early stages of an 
epidemic. Joining regions together using multilevel models can allows 
information to be shared between regions in a natural way, improving parameter 
estimates while still permitting between group variation.

In this article, we use a multilevel model to estimate the effect of non 
pharmaceutical interventions (NPIs) on the transmissibility of Covid-19. 
We consider the same setup as @Flaxman2020: attempting to estimate the effect of 
NPIs that were implemented in March 2020 in 11 European countries using daily death data, during the 
first wave of Covid-19. The same set of NPIs and countries are used here.

This example is not intended to be a fully rigourous statistical analysis. 
Rather, the intention is to demonstrate partial pooling of parameters in 
**epidemia** and how to infer their effect sizes. The artical also shows how 
to forecast observations into the future, and how to undertake counterfactual 
analyses.

Begin by loading required packages. **dplyr** will be used to manipulate 
the dataset, while **rstanarm** is used to define prior distributions.
```{r load-packages, message = FALSE}
library(dplyr)
library(epidemia)
library(rstanarm)
```


## Data
<hr>

We use a dataset `EuropeCovid2`, which is provided by **epidemia**. This contains 
daily death and case data in the 11 countries concerned up until the 1^st^ July 
2020. The data derives from the WHO COVID-19 explorer as of the 5^th^ of January 
2021. This differs from the data used in @Flaxman2020, because case and death counts 
have been adjusted retrospectively as new information came to light. **epidemia** 
also has a dataset `EuropeCovid` which contains the same data as that in @Flaxman2020, 
and this could alternatively be used for this exercise. 

`EuropeCovid2` also contains binary variables representing the set of five NPIs considered 
in @Flaxman2020. These correspond to the closing of schools and universities, the 
banning of public events, encouraging social distancing, requiring self isolation
if ill, and finally the implementation of full lockdown. The dates at which these 
policies were enacted are exactly the same as those used in @Flaxman2020. 

Load the dataset as follows.
```{r load-data}
data("EuropeCovid2")
data <- EuropeCovid2$data
head(data)
data <- data %>% ungroup() %>% group_by(id) %>% arrange(id) # remove later
```

Recall that for each region, **epidemia** will use the earliest date in `data` 
as the first date to begin seeding infections. Therefore, we must choose an 
appropriate start date for each group. One option is to use the same rule as in @Flaxman2020,
and assume that seeding begins in each country 30 days prior to 
observing 10 cumulative deaths. To do this, we filter the dataframe as follows.
```{r choose-start-date}
data <- filter(data, date > date[which(cumsum(deaths) > 10)[1] - 30])
```
This leaves the following assumed start dates.
```{r show-start-dates, message = FALSE}
summarise(data, start = min(date), end = max(date))
```
Although `data` contains observations up until the end of June, we use only 
a subset of the data, so that we can hold out the rest to demonstrate forecasting.
Following @Flaxman2020, we use data up until the 5^th^ May.
```{r choose-end-date}
data <- filter(data, date < as.Date("2020-05-05"))
```

## Transmission

We start by considering the transmission model, and then move on to the model 
for daily deaths in the next section. Let $I^{(m)}_{1}, \ldots, I^{(m)}_{5}$ be a set of binary vectors such 
that $I^{(m)}_{i,t} = 1$ if the $i$^th^ NPI has been implemented in the $m$^th^ 
country by time $t$, and be $0$ otherwise. We parameterise reproduction numbers 
as 
\begin{equation}
R^{(m)}_{t} = R' g^{-1}\left(b^{(m)}_0 + \sum_{i=1}^{5}\left(\beta_i + b^{(m)}_i\right)I^{(m)}_{i,t}\right),
\end{equation}
where $R' = 3.25$ and $g$ is the logit-link. Parameters $b^{(m)}_0$ are country intercepts, and 
each $b^{(m)}_i$ is a country effects for the $i$^th^ NPI. The intercepts allow
countries to have differing $R_0$'s, and models variations in the inherent 
transmissibility of Covid-19 in each population.
$\beta_i$ is a fixed effect for the $i$^th^ NPI. This 
models the average effect of an NPI across all countries considered.

Fixed effects can be assigned parameters flexibly in **epidemia**. The NPIs 
considered were implemented in quick succession across the countries 
considered, often with some being enacted simultaneously. Therefore 
they are *highly colinear* and may be difficult to infer with uninformative 
priors. In particular, it is apriori unlikely that these NPIs served to increase
transmission rates significantly, while they plausibly had a significant effect 
on reducing transmission. A symmetric prior like the Gaussian does not capture 
this intuition, and increases the difficulty in inferring effects, because they 
are more able to offset each other. This motivated the prior used in @Flaxman2020, 
which was a Gamma shifted to have support other than zero.

We partially pool all country specific parameters by letting
\begin{equation}
b^{(m)}_i \sim N(0, \sigma_i),
\end{equation}
where the standard deviation $\sigma_i$ are given independent Gamma priors with 
shape 1 and scale 0.25.


```{r}
rt <- epirt(
  formula = R(country, date) ~ 0 + (1 + public_events + schools_universities + self_isolating_if_ill + social_distancing_encouraged + lockdown || country) + public_events + schools_universities + self_isolating_if_ill + social_distancing_encouraged + lockdown,
  prior = shifted_gamma(shape=1/6, scale = 1, shift = log(1.05)/6),
  prior_covariance = decov(shape = c(2, rep(0.5, 5)),scale=0.25),
  link = scaled_logit(6.5)
)
```

## Infections

We keep infections simple here by using the basic version of the model. 
That is to say that infections are taken to be a deterministic function of 
seeds and reproduction numbers, propagated by the renewal process. Extensions 
to modeling infections as parameters and adjustments for the susceptible 
population are not considered. The model is defined as follows.

```{r inf-model}
inf <- epiinf(gen = EuropeCovid$si, seed_days = 6)
```

`EuropeCovid$si` is a numeric vector giving the serial interval used in 
@Flaxman2020. As in that work, we make no distinction between the generation 
distribution and serial interval here.

## Observations
<hr>

We are left to define the model for daily deaths. We use a simple intercept model, 
just as we did for cases in the Flu example. Recall that this assumes that the 
nfection fatality rate (IFR) is constant over time. Our model is as follows.
```{r deaths-model}
deaths <- epiobs(
  formula = deaths ~ 1,
  i2o = EuropeCovid2$inf2death,
  prior_intercept = normal(0,0.2),
  link = scaled_logit(0.02)
)
```
By using `link = scaled_logit(0.02)`, we let the IFR range between $0\%$ and 
$2\%$. In conjunction with the symmetric prior on the intercept, this gives 
the IFR a prior mean of $1\%$. `EuropeCovid2$inf2death` is a numeric vector 
giving the same distribution for the time from infection to death as that used in 
@Flaxman2020. 

## Model Fitting
<hr>
Here, we use variational Bayes (VB) to fit the model as opposed to full MCMC 
sampling. This is because full MCMC sampling of a joint model of this size 
is computationally demanding, due in part to renewal processes having to be computed 
for each region and for each evaluation of the likelihood and its derivatives. 
MCMC should generally be used for final inference. Nonetheless, VB allows rapid 
iteration of models and may lead to reasonable estimates of effect sizes. For 
this example, we have also run full MCMC, and the inferences reported here are 
not substantially different. 

### Prior Check
<hr>

It is useful to check the implied prior distribution on reproduction numbers 
before fitting a full model. This can catch obvious mistakes that can occur 
when specifying the transmission model, and can help affirm that the prior is 
reasonable.

In **epidemia** we can do this by using the `priorPD = TRUE` flag in 
`epim()`. This discards the likelihood component of the posterior, leaving 
just the prior. If we `alogrithm = "sampling"`, HMC is used to sample parameters
from the prior. Here we use sampling rather than VB, partly because 
sampling from the prior is relatively quick: it is the likelihood that is 
expensive to evaluate. In addition, we have defined Gamma priors on some 
coefficients, which are generally poorly approximated by VB.

```{r collect-args}
args <- list(rt=rt, inf=inf, obs=deaths, data=data, seed=12345, refresh=0)
```


```{r prior-sampling, cache=TRUE}
options(mc.cores = parallel::detectCores())
pr_args <- c(args, list(algorithm="sampling", iter=1e3, prior_PD=TRUE))

fm_prior <- do.call(epim, pr_args)
```

Below we plot approximate samples of $R_{t,m}$ from the prior distribution. 

```{r prior-check, echo = FALSE, out.width = "60%"}
p <- plot_rt(fm_prior, step=T, groups ="United_Kingdom")
ggsave("../man/figures/multilevel-prior-plot.png", width=5, height=5)
knitr::include_graphics("../man/figures/multilevel-prior-plot.png")
```


### Approximating the Posterior

Recall that the model will be fit using VB. In particular, `algorithm = "fullrank"`
is used. This is generally 
preferable to `"meanfield"` for these models - largely because `"meanfield"` 
ignores posterior correlations. We decrease the parameter `tol_rel_obj` from 
its default, and increase the number of iterations to aid convergence.

```{r fit-model, cache=TRUE}
args$algorithm <- "fullrank"
args$iter <- 5e4
args$tol_rel_obj <- 1e-3

fm <- do.call(epim, args)
```


A first step in evaluating the model fit is to perform posterior predictive 
checks. This is to confirm that the model adequately explains the observed 
daily deaths in each region. This can be done using the command 
`plot_obs(fm, type = "deaths")`. After some formatting to the resulting ggplot 
object, the plot is shown in Figure \@ref(fig:obs-plots).

```{r obs-plots, fig.cap = "Posterior predictive checks. Observed data is plotted with credible intervals derived from the approximated posterior.", out.width="100%", echo = FALSE, message=FALSE}
p <- plot_obs(fm, type = "deaths", levels = c(50, 95))
ggsave("../man/figures/multilevel-obs-plot.png", width=10, height=5)
knitr::include_graphics("../man/figures/multilevel-obs-plot.png")
```

Figure \@ref(fig:obs-plots) suggest that the epidemic was bought under control 
in each group considered, with reproduction numbers falling below one everywhere.
Indeed, we would expect that the posterior reproduction numbers fall below one 
in each region. \@ref(fig:rt-plots) confirms this.

```{r rt-plots, fig.cap = "Credible intervals for reproduction numbers. These are step functions because $R_t$ is parameterised only in terms of NPIs.", out.width = "100%", echo = FALSE, message=FALSE}
p <- plot_rt(fm, step = T, levels = c(50,95))
ggsave("../man/figures/multilevel-rt-plot.png", width=10, height=6)
knitr::include_graphics("../man/figures/multilevel-rt-plot.png")
```


## Effect Sizes

In **epidemia**, estimated effect sizes can be visualised using the `plot.epimodel` 
method. This serves a similar purpose to `plot.stanreg` in **rstanarm**, 
providing an interface to the **bayesplot** package. The models in **epidemia** 
often have many parameters, some of which pertain to a particular part of the model 
(i.e. transmission), and some which pertain to particular 
groups (i.e., country-specific terms). Therefore `plot.epimodel` has 
arguments `par_models`, `par_types` and `par_groups`, which restrict the 
parameters considered to particular parts of the model.

As an example, one can plot credible intervals for the global 
coefficients $\beta_i$ using the command 
`plot(fm, par_models = "R", par_types = "fixed")`. This leads to 
\@ref(fig:effect-plots).

```{r effect-plots, fig.cap = "Effect sizes for global coefficients.", out.width = "70%", echo = FALSE}
p <- plot(fm, par_models = "R", par_types = "fixed")
ggsave("../man/figures/multilevel-effect-plots.png", width=5, height=3)
knitr::include_graphics("../man/figures/multilevel-effect-plots.png")
```

Figure \@ref(fig:effect-plots) shows a large negative coefficient for lockdown, 
suggesting that this is on average the most effective intervention. 
The effect of banning public events is the next largest, while the other NPIs appear closer 
to zero. Note that \@ref(fig:effect-plots) shows only global coefficients, and does 
not show inferred effects in any given country. To assess the latter, one must 
instead consider the quantities $\beta_i + b^{(m)}_i$. We do this by 
extracting the underlying draws using `as.matrix.epimodel`, as is done below 
for Italy.
```{r total-effects-parsing}
beta <- as.matrix(fm, par_models = "R", par_types = "fixed")
b <- as.matrix(fm, regex_pars = "^R\\|b", par_groups = "Italy")
mat <- cbind(b[,1], beta + b[,2:6])
colnames(mat) <- c("Intercept", "public_events", "schools_universities", 
                  "self_isolating_if_ill", "social_distancing_encouraged", "lockdown")
```

Calling `bayesplot::mcmc_intervals(mat)` gives 
Figure  \@ref(fig:total-effects).
```{r total-effects, fig.cap = "Total effect Sizes", out.width = "70%", echo = FALSE}
p <- bayesplot::mcmc_intervals(mat) + ggplot2::ggtitle("Italy")
ggsave("../man/figures/multilevel-total-effect-plots.png", width=5, height=3)
knitr::include_graphics("../man/figures/multilevel-total-effect-plots.png")
```

Figure \@ref(fig:total-effects) has relatively narrow intervals for many of the 
effect sizes. This appears to be an artifact of using variational Bayes. In 
particular, when repeating this analysis with full MCMC, we observe that the 
intervals for all policies other than lockdown overlap with zero.

Consider now the role of partial pooling in this analysis. Figure 
\@ref(fig:rt-plots) shows that Sweden did enough to reduce $R$ below one. However, 
it did so without a full lockdown. Given the small effect sizes for other NPIs, 
the model must explain Sweden using the country-specific terms. Figure \@ref(fig:interval-plots)
shows estimated seeds, intercepts and the effects of banning public events for each 
country. Sweden has a lower intercept than other terms which in turn suggests a 
lower $R_0$ - giving the effects less to do to explain Sweden. There 
is greater variability in seeding, because the magnitude of future infections 
becomes less sensitive to initial conditions when the rate of growth is lower. 
Figure \@ref(fig:interval-plots) shows that the model estimates a large negative 
coefficient for public events in Sweden. This is 
significantly larger then the effects for other policies - which are not reported 
here.

```{r interval-plots, fig.cap = "Seeds, intercepts and public polic effects for each country", echo=FALSE, warning=FALSE, message=FALSE, out.width = "100%"}
p_seeds <- plot(fm, "areas", regex_pars = "seeds")
p_int <- plot(fm, regex_pars = "R\\|b\\[\\(Int", par_types = "random", par_groups=fm$groups)
mat <- as.matrix(fm, regex_pars = "(^R\\|pub)|(^R\\|b\\[public)", par_groups = fm$groups)
mat <- sweep(mat[,-1], MARGIN=1, STATS = mat[,1], FUN = "+")
p_pub <- bayesplot::mcmc_intervals(mat)

labels = fm$groups
p_seeds <- p_seeds + ggtitle("Seeds") + ggplot2::scale_y_discrete(labels=labels)
p_int <- p_int + ggtitle("Intercepts") + theme(axis.text.y = element_blank()) + ggplot2::scale_y_discrete(labels=labels)
p_pub <- p_pub + ggtitle("Public Events") + theme(axis.text.y = element_blank()) + ggplot2::scale_y_discrete(labels=labels)
p <- gridExtra::arrangeGrob(p_seeds, p_int, p_pub, nrow=1, padding=unit(0), widths = c(1.5,1,1))
ggsave("../man/figures/multilevel-interval-plots.png", plot=p, width=10, height=5)
knitr::include_graphics("../man/figures/multilevel-interval-plots.png")
```

## Forecasting


```{r forecasting, out.width = "100%"}
newdata <- EuropeCovid2$data
newdata <- filter(newdata, date > date[which(cumsum(deaths) > 10)[1] - 30])
plot_obs(fm, type = "deaths", newdata = newdata, groups = c("United_Kingdom", "Italy"))
```


## Counterfactuals


Counterfactuals are also easy. One simply has to modify the dataframe used. For 
example, values of covariates can be adjusted. In this case we shift all NPIs 
back three days.
```{r counterfactuals-newdata}
shift_earlier <- function(x, k) c(x[-(1:k)], rep(1,k))
days <- 3

newdata <- mutate(newdata,
  lockdown = shift_earlier(lockdown, days),
  public_events = shift_earlier(public_events, days),
  social_distancing_encouraged = shift_earlier(social_distancing_encouraged, days),
  self_isolating_if_ill = shift_earlier(self_isolating_if_ill, days),
  schools_universities = shift_earlier(schools_universities, days)
)
```

Figure \@ref(fig:counterfactuals) visualises the counterfactual scenario of all 
policies being implemented in the UK three days earlier. Deaths are projected 
over both the in-sample period, and the out of sample period. The left plot
is obtained using `plot_obs(fm, type = "deaths", newdata=newdata, groups = "United_Kingdom")`,
while the right plot adds the `cumulative = TRUE` argument.

```{r counterfactuals, out.width = "100%", fig.cap = "Counterfactual for UK where all NPIs implemented 3 days earlier. Left is daily deaths, right is cumulative.", echo=FALSE}
p1 <- plot_obs(fm, type = "deaths", newdata=newdata, groups = "United_Kingdom")
p2 <-plot_obs(fm, type = "deaths", newdata=newdata, groups = "United_Kingdom", cumulative=T)
p <- gridExtra::arrangeGrob(p1, p2, nrow = 1)
ggsave("../man/figures/multilevel-counterfactual.png", plot=p, width = 10, height = 6)
knitr::include_graphics("../man/figures/multilevel-counterfactual.png")
```


# References

</div>
